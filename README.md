# Proyecto de Generación de Texto

[Generacion_de_Texto.pdf](https://github.com/user-attachments/files/17970134/Generacion_de_Texto.pdf)

## Descripción

Este proyecto tiene como objetivo generar texto utilizando dos modelos de lenguaje: **GPT-2** y **Qwen2-0.5B**. Se implementa en Python y permite comparar los resultados de ambos modelos en la generación de texto a partir de un conjunto de entradas específicas proporcionadas por el usuario. El proyecto está diseñado para facilitar la evaluación y comparación de los modelos de generación de texto, ayudando a entender cómo cada uno maneja la creatividad, coherencia y relevancia del texto generado.

## Modelos Utilizados

1. **GPT-2 (Generative Pre-trained Transformer 2)**:
   - Un modelo de lenguaje desarrollado por OpenAI. Es uno de los modelos más conocidos y utilizados para tareas de generación de texto.
   - **Versión**: GPT-2, implementado en el proyecto para generar respuestas coherentes basadas en prompts proporcionados.

2. **Qwen2-0.5B**:
   - Un modelo de lenguaje más reciente que se utiliza para generar texto en tareas similares. A pesar de tener un tamaño menor en comparación con GPT-2, es capaz de generar textos creativos y coherentes.
   - **Versión**: Qwen2-0.5B, implementado en este proyecto para comparar su desempeño con el de GPT-2.

## Requisitos

- **Python 3.7+**
- **Librerías necesarias**:
  - `requests`
  - `json`

Puedes instalar las dependencias necesarias usando `pip`:

```bash
pip install requests
```
